{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100da121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node a4a5db65-ab23-417b-975e-12649f3406c8"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tdmclient import ClientAsync\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009eebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librairy for kalman\n",
    "pip install filterpy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a83421b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.5/78.5 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\administrateur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.64.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae43392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvisgraph\n",
      "  Downloading pyvisgraph-0.2.1.tar.gz (8.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Installing collected packages: pyvisgraph\n",
      "  Running setup.py install for pyvisgraph: started\n",
      "  Running setup.py install for pyvisgraph: finished with status 'done'\n",
      "Successfully installed pyvisgraph-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: pyvisgraph is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n"
     ]
    }
   ],
   "source": [
    "pip install pyvisgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "809aa1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-pythonNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "     --------------------------------------- 35.6/35.6 MB 13.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\administrateur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7460630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from filterpy.common import Q_discrete_white_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1064e9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\administrateur\\appdata\\roaming\\python\\python311\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\administrateur\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-contrib-python) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-contrib-python --user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c43fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables\n",
    "#robot_state[0,0,0,0] # [x,y,vx,vy]\n",
    "#pos_cam=[0,0]\n",
    "#new_image=false\n",
    "#Ts = 0.1\n",
    "#qp = 0.04 # variance on position state\n",
    "#rp = 0.25 # variance on position measurement\n",
    "\n",
    "#q_nu= 0.04 #variance on speed state\n",
    "#r_nu=0.25 #variance on speed measurement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2356e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy import ndimage\n",
    "\n",
    "class Map:\n",
    "    #compute_globalmap(self,image,robot_size,start_id=0,goal_id=1):\n",
    "    #  Generate globalmap with obstacle inflation: 0:free 1:occupied 2:start 3:goal\n",
    "    #  return self.globalmap\n",
    "    #compute_pixel_to_distance(self):\n",
    "    #  compute real world distance between two neighborhood pixels;unit:mm\n",
    "    #  **only have the value when goal is detected successfully\n",
    "    #  return self.pixel_to_distance\n",
    "    #compute_start(self,image, start_id=0):\n",
    "    #  Detect start by aruco marker\n",
    "    #  Return start position in (x,y) coordinate; if not detected return None\n",
    "    #  return self.start\n",
    "    #compute_goal(self,image, goal_id=1):\n",
    "    #  Detect goal by aruco marker\n",
    "    #  Return goal position in (x,y) coordinate; if not detected return None\n",
    "    #  return self.goal\n",
    "    #get_pixel_to_distance(self):\n",
    "    #  return self.pixel_to_distance\n",
    "    #get_globalmap(self):\n",
    "    #  return self.globalmap\n",
    "    #get_start(self):\n",
    "    #  return self.start\n",
    "    #get_goal(self):\n",
    "    #  return self.goal\n",
    "    \n",
    "    def compute_globalmap(self, image, robot_size=7.5, start_id=0, goal_id=1):\n",
    "        # Generate globalmap with obstacle inflation: 0:free 1:occupied 2:start 3:goal\n",
    "        # height, width = image.shape[:2]\n",
    "\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Simple threshold method\n",
    "        # ret,thresh = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "        # Otsu's thresholding after Gaussian filtering\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Generate Global map\n",
    "        # from 0,255 convert to 0(free),1(occupied);change to (x,y) coordinate\n",
    "        temp_globalmap = np.transpose(np.array(thresh < 255, dtype=int))\n",
    "\n",
    "        # Detect start and goal by aruco marker\n",
    "        # Return start and goal position in (x,y) coordinate; if not detected return None\n",
    "        # start_id: start aruco marker id\n",
    "        # goal_id=: goal aruco marker id\n",
    "\n",
    "        # Define aruco marker detector\n",
    "        arucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "        arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "        # Detect aruco marker\n",
    "        (corners, ids, rejected) = cv2.aruco.detectMarkers(image, arucoDict, parameters=arucoParams)\n",
    "        # print(corners, ids, rejected)\n",
    "        start = None\n",
    "        goal = None\n",
    "        s = 5\n",
    "        if ids is not None:\n",
    "            for corner, number in zip(corners, ids):\n",
    "                (topLeft, topRight, bottomRight, bottomLeft) = corner[0].astype(int)\n",
    "                # print(topLeft, topRight, bottomRight, bottomLeft)\n",
    "                centerpoint = (int((topLeft[0] + bottomRight[0]) / 2), int((topLeft[1] + bottomRight[1]) / 2))\n",
    "                if number == start_id:\n",
    "                    start = centerpoint\n",
    "                    # print(\"start:\",start)\n",
    "                    # print(topLeft, topRight, bottomRight, bottomLeft)\n",
    "                    temp_globalmap[topLeft[0] - s:bottomRight[0] + s, topLeft[1] - s:bottomRight[1] + s] = 2\n",
    "                    # print(temp_globalmap[bottomRight[0]-2:topLeft[0]+2,topLeft[1]-2:bottomRight[1]+2])\n",
    "\n",
    "                elif number == goal_id:\n",
    "                    goal = centerpoint\n",
    "                    # print(\"goal:\",goal)\n",
    "                    # print(topLeft, topRight, bottomRight, bottomLeft)\n",
    "                    temp_globalmap[topLeft[0] - s:bottomRight[0] + s, topLeft[1] - s:bottomRight[1] + s] = 3\n",
    "                    # print(temp_globalmap[bottomRight[0]-2:topLeft[0]+2,topLeft[1]-2:bottomRight[1]+2])\n",
    "                    self.goal_topLeft = topLeft\n",
    "                    self.goal_topRight = topRight\n",
    "                    pixel_to_distance = self.compute_pixel_to_distance()\n",
    "                    # print(\"pixel_to_distance:\",pixel_to_distance)\n",
    "\n",
    "                else:\n",
    "                    temp_globalmap[bottomRight[0] - s:topLeft[0] + s, topLeft[1] - s:bottomRight[1] + s] = 0\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        globalmap = temp_globalmap.copy()\n",
    "\n",
    "        if start is None:\n",
    "            print(\"NOT detect start point\")\n",
    "        else:\n",
    "            globalmap[temp_globalmap == 2] = 0\n",
    "        if goal is None:\n",
    "            print(\"NOT detect goal point\")\n",
    "        else:\n",
    "            globalmap[temp_globalmap == 3] = 0\n",
    "\n",
    "        # obstacle_map:the map only have obstacle inside, no start and goal\n",
    "        self.obstacle_map = globalmap.copy()\n",
    "\n",
    "        # obstacle inflation\n",
    "        # 3x3 structuring element with connectivity 2\n",
    "        struct = ndimage.generate_binary_structure(2, 2)\n",
    "        # robot_size:radius of robot(unit:mm)\n",
    "        margin = int(robot_size / pixel_to_distance)+1\n",
    "        #margin=1\n",
    "        globalmap = ndimage.binary_dilation(globalmap, structure=struct, iterations=margin).astype(globalmap.dtype)\n",
    "\n",
    "        # add start and goal\n",
    "        globalmap[temp_globalmap == 2] = 2\n",
    "        globalmap[temp_globalmap == 3] = 3\n",
    "\n",
    "        self.globalmap = globalmap\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "\n",
    "        return self.globalmap\n",
    "    \n",
    "    def compute_pixel_to_distance(self):\n",
    "        #for get pixel_to_ditance value, use function \"get_pixel_to_distance\"\n",
    "        #aruco marker:50mmx50mm\n",
    "        #pixel_to_distance:return real world distance between two neighborhood pixels;unit:mm\n",
    "        pixel_to_distance=50/math.dist(self.goal_topLeft,self.goal_topRight) #unit:mm\n",
    "        print(\"Distance between two pixel is:\",pixel_to_distance,\"mm\")\n",
    "        \n",
    "        self.pixel_to_distance=pixel_to_distance\n",
    "        \n",
    "        return self.pixel_to_distance\n",
    "        \n",
    "    \n",
    "    def get_pixel_to_distance(self):\n",
    "        return self.pixel_to_distance\n",
    "    \n",
    "    def get_globalmap(self):\n",
    "        return self.globalmap\n",
    "    \n",
    "    def get_start(self):\n",
    "        #get the center point of start point\n",
    "        if self.start is None: print(\"NOT detect start point\") \n",
    "        else:pass\n",
    "        return self.start\n",
    "    \n",
    "    def get_goal(self):\n",
    "        #get the center point of goal point\n",
    "        if self.goal is None: print(\"NOT detect goal point\") \n",
    "        else:pass\n",
    "        return self.goal\n",
    "\n",
    "    def compute_start(self,image, start_id=0):\n",
    "        #Detect start by aruco marker\n",
    "        #Return start position in (x,y) coordinate; if not detected return None\n",
    "        #start_id: start aruco marker id\n",
    "\n",
    "        #Define aruco marker detector\n",
    "        arucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "        arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "        #Detect aruco marker\n",
    "        (corners, ids, rejected) = cv2.aruco.detectMarkers(image, arucoDict,parameters=arucoParams)\n",
    "        # print(corners, ids, rejected)\n",
    "        start=None\n",
    "        if ids is not None:\n",
    "            for corner,number in zip(corners,ids):\n",
    "                (topLeft, topRight, bottomRight, bottomLeft) = corner[0].astype(int)\n",
    "                #print(topLeft, topRight, bottomRight, bottomLeft)\n",
    "                centerpoint=(int((topLeft[0]+bottomRight[0])/2),int((topLeft[1]+bottomRight[1])/2))\n",
    "                if number==start_id:\n",
    "                    start=centerpoint\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "        else: pass\n",
    "        if start is None: print(\"NOT detect start point\") \n",
    "        else:print(\"start position is:\",start)\n",
    "        self.start=start\n",
    "\n",
    "        return self.start\n",
    "\n",
    "    def compute_goal(self,image, goal_id=1):\n",
    "        #Detect goal by aruco marker\n",
    "        #Return goal position in (x,y) coordinate; if not detected return None\n",
    "        #goal_id=: goal aruco marker id\n",
    "\n",
    "        #Define aruco marker detector\n",
    "        arucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "        arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "        #Detect aruco marker\n",
    "        (corners, ids, rejected) = cv2.aruco.detectMarkers(image, arucoDict,parameters=arucoParams)\n",
    "        # print(corners, ids, rejected)\n",
    "        goal=None\n",
    "        if ids is not None:\n",
    "            for corner,number in zip(corners,ids):\n",
    "                (topLeft, topRight, bottomRight, bottomLeft) = corner[0].astype(int)\n",
    "                #print(topLeft, topRight, bottomRight, bottomLeft)\n",
    "                centerpoint=(int((topLeft[0]+bottomRight[0])/2),int((topLeft[1]+bottomRight[1])/2))\n",
    "                if number==goal_id:\n",
    "                    goal=centerpoint\n",
    "                    self.goal_topLeft=topLeft\n",
    "                    self.goal_topRight= topRight\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "        else: pass\n",
    "        if goal is None: print(\"NOT detect goal point\") \n",
    "        else:print(\"goal position is:\",goal)\n",
    "        self.goal=goal\n",
    "        \n",
    "        return self.goal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2edd20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vertex(globalmap):\n",
    "\n",
    "    #get rid of start and goal area\n",
    "    globalmap[globalmap==2]=0\n",
    "    globalmap[globalmap==3]=0\n",
    "    \n",
    "    globalmap=np.uint8(np.dot(np.transpose(globalmap),255))\n",
    "\n",
    "    # apply canny edge detection\n",
    "    edges = cv2.Canny(globalmap, 60, 160)\n",
    "\n",
    "    # apply morphology close\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    morph = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # get contours \n",
    "    contours = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # get vertices\n",
    "    vertices=[]\n",
    "    for i in range(len(contours[0])):\n",
    "        peri = cv2.arcLength(contours[0][i], True)\n",
    "        approx = cv2.approxPolyDP(contours[0][i], 0.01 * peri, True)\n",
    "        vertice=[]\n",
    "        for i in range(len(approx)):\n",
    "            vertice.append(approx[i][0].tolist())\n",
    "        vertices.append(np.array(vertice))\n",
    "    \n",
    "    \n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa2ed384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_robot_position(image,robot_id=3):\n",
    "    #Detect robot position by aruco marker\n",
    "    #Return robot position; if not detected return None\n",
    "    #robot_id: robot aruco marker id\n",
    "\n",
    "    #Define aruco marker detector\n",
    "    arucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "    arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "    robot=None\n",
    "\n",
    "    #Detect Aruco marker\n",
    "    (corners, ids, rejected) = cv2.aruco.detectMarkers(image, arucoDict,parameters=arucoParams)\n",
    "    # print(corners, ids, rejected)\n",
    "    if ids is not None:\n",
    "        #print(\"aruco marker detected:\",ids)\n",
    "        for corner,number in zip(corners,ids):\n",
    "            (topLeft, topRight, bottomRight, bottomLeft) = corner[0]\n",
    "            centerpoint=(int((topLeft[0]+bottomRight[0])/2),int((topLeft[1]+bottomRight[1])/2))\n",
    "            if number==robot_id:\n",
    "                robot_position=centerpoint\n",
    "                angle=angle_calculate(topLeft,topRight)\n",
    "                break\n",
    "            else:pass\n",
    "    else:pass\n",
    "    \n",
    "    \n",
    "    return np.array(robot_position)\n",
    "\n",
    "def angle_calculate(pt1,pt2):  # function which returns angle between two points in the range of 0-359\n",
    "    angle_list = list(range(0,360,1))\n",
    "    x=pt2[0]-pt1[0] \n",
    "    y=pt2[1]-pt1[1]\n",
    "    angle=int(math.degrees(math.atan2(y,x))) #takes 2 points nad give angle with respect to horizontal axis in range(-180,180)\n",
    "    angle = angle_list[angle]\n",
    "    \n",
    "    return int(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a6066f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman(current_state, pos_cam, motor_speed):\n",
    "    \n",
    "    #estimate x-y position with velocity\n",
    "    #measurements and camera postion measurement\n",
    "    f = KalmanFilter (dim_x=4, dim_z=4)\n",
    "\n",
    "    # initial position\n",
    "    f.x= np.transpose(current_state)\n",
    "    print(current_state)\n",
    "    print(f.x)\n",
    "    \n",
    "    #state transition matrix\n",
    "   \n",
    "    f.F = np.array([[1, 0, Ts, 0],\n",
    "              [0, 1, 0, Ts], \n",
    "              [0, 0, 1, 0],\n",
    "              [0, 0, 0, 1]])\n",
    "\n",
    "    #measurement function H\n",
    "    f.H = np.array([[1, 0, 0, 0],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1]])\n",
    "\n",
    "    #covariance matrix P\n",
    "    f.P = np.array([[qp, 0, 0, 0], \n",
    "              [0, qp, 0, 0], \n",
    "              [0, 0, q_nu, 0], \n",
    "              [0, 0, 0, q_nu]])\n",
    "\n",
    "    #measurement noise R (scalar)\n",
    "    f.R = np.array([[rp, 0, 0, 0],\n",
    "                [0, rp, 0, 0],\n",
    "                [0, 0, r_nu, 0],\n",
    "                [0, 0, 0, r_nu]])\n",
    "\n",
    "    #process noise Q\n",
    "    f.Q = Q_discrete_white_noise(dim=2, dt=0.1, var=0.13)\n",
    "    \n",
    "    if(new_image): #if image is up to date, take position from camera\n",
    "        print(motor_speed)\n",
    "        print(pos_cam)\n",
    "        z = np.transpose(np.array([pos_cam[0],pos_cam[1], motor_speed[0],motor_speed[1]]))\n",
    "    else:\n",
    "        pos=[current_state[0], current_state[1]] #if image outdated, use state position instead of camera position\n",
    "        z = np.array(pos, motor_speed)\n",
    "    \n",
    "    f.predict()\n",
    "    f.update(z)\n",
    "\n",
    "    #return state and covariance matrix\n",
    "    return f.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad08031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global path\n",
    "\n",
    "def global_path(start_pos, goal_pos, global_map):\n",
    "\n",
    "    import pyvisgraph as vg\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    start = np.array(start_pos)#np.array([0.5,0.5])\n",
    "    goal = np.array(goal_pos)#np.array([5.25,6])\n",
    "\n",
    "    start_point = vg.Point(start[0], start[1])\n",
    "    goal_point = vg.Point(goal[0], goal[1])\n",
    "\n",
    "    vertices = np.array(global_map)#np.array([[[1,2],[3,2],[3,4],[1,4]],[[4,4],[6,4],[5,5]]])\n",
    "   \n",
    "\n",
    "    vertices = np.asarray(vertices)\n",
    "    #print(vertices)\n",
    "\n",
    "    #plt.plot(vertices)\n",
    "    #plt.show\n",
    "\n",
    "    # Automate the creation of vg.Points for the obstacles\n",
    "\n",
    "    max_vertices = 0\n",
    "\n",
    "    for i in range(len(vertices)):\n",
    "        if(len(vertices[i])>max_vertices):\n",
    "            max_vertices = len(vertices[i])\n",
    "\n",
    "    polygons = [[0 for i in range(max_vertices+1)] for j in range(len(vertices))]\n",
    "\n",
    "    for i in range(len(vertices)):\n",
    "        for j in range(len(vertices[i])):\n",
    "            polygons[i][j] = vg.Point(vertices[i][j][0],vertices[i][j][1])\n",
    "        polygons[i][(len(vertices[i])):(max_vertices+1)] = [polygons[i][0] for k in range(len(vertices[i]),max_vertices+1)]\n",
    "        #polygons[i][range(len(vertices[i]),max_vertices)] = polygons[i][0]\n",
    "    \n",
    "    #print(polygons)\n",
    "\n",
    "    graph = vg.VisGraph()\n",
    "    graph.build(polygons)\n",
    "    #graph.buffer(margin,join_style=2)\n",
    "\n",
    "    shortest_path = graph.shortest_path(start_point,goal_point)\n",
    "\n",
    "    print(shortest_path)\n",
    "\n",
    "    polygons_x = np.empty((len(polygons),len(polygons[1])+1))\n",
    "    polygons_y = np.empty((len(polygons),len(polygons[1])+1))\n",
    "\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(len(polygons[i])):\n",
    "            polygons_x[i][j] = polygons[i][j].x\n",
    "            polygons_y[i][j] = polygons[i][j].y\n",
    "        polygons_x[i][len(polygons[1])] = polygons_x[i][0]\n",
    "        polygons_y[i][len(polygons[1])] = polygons_y[i][0]\n",
    "\n",
    "    shortest_path_x = np.empty(len(shortest_path))\n",
    "    shortest_path_y = np.empty(len(shortest_path))\n",
    "    \n",
    "    shortest = [[0 for i in range(2)] for j in range(len(shortest_path))]\n",
    "\n",
    "    for i in range(len(shortest_path)):\n",
    "        shortest_path_x[i] = shortest_path[i].x\n",
    "        shortest_path_y[i] = shortest_path[i].y\n",
    "        shortest[i][0] = shortest_path[i].x\n",
    "        shortest[i][1] = shortest_path[i].y\n",
    "\n",
    "    plt.plot(shortest_path_x,shortest_path_y)\n",
    "    plt.plot(polygons_x.T,polygons_y.T)\n",
    "    plt.show()\n",
    "    return shortest\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f7c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_nav(path):\n",
    "    global index,speed_left,speed_right,direction\n",
    "    \n",
    "    #constantes\n",
    "    v_max=200#mm/s\n",
    "    #v_min=20\n",
    "    Diameter=94#mm\n",
    "    goal_margin=30#mm\n",
    "    threshold=0.3\n",
    "    \n",
    "    #just to tune by test, names wrong\n",
    "    Kp_d=0.1\n",
    "    #CHECK GOAL\n",
    "    if math.sqrt((robot_state[0]-path[index,0])**2+(robot_state[1]-path[index,1])**2)<goal_margin:\n",
    "        if index+1>=np.size(path[:,0]):\n",
    "            print('arrived')\n",
    "            state=2\n",
    "            return 0,0#works only in a function\n",
    "        else:\n",
    "            index=index+1\n",
    "            print('goal : ',index)\n",
    "    \n",
    "    #MOTORS\n",
    "    obj_angle=np.arctan2(path[goal,1]-robot_state[1],path[goal,0]-robot_state[0])\n",
    "    \n",
    "    if abs(obj_angle-direction)>threshold:\n",
    "        vitesse=0#-Kd_v*abs(obj_angle-direction[present])+Kp_v*abs(50-vitesse[present])#vitesse[present]\n",
    "        if vitesse<0:vitesse=0##v_min\n",
    "    else:\n",
    "        vitesse=50#-Ki_v*abs(50-vitesse[present])\n",
    "    \n",
    "    #derror=obj_dir(*position[present,:],*path[goal,:])+obj_dir(*position[present-1,:],*path[goal,:])-direction[present]-direction[present-1]\n",
    "    speed_left=-(Kp_d*(obj_angle-direction))*Diameter#vitesse[present+1]    #0.2*(speed_l[present]+speed_l[present-1])/2    #-Kd_d*derror\n",
    "    speed_right=(Kp_d*(obj_angle-direction))*Diameter#vitesse[present+1]    #0.2*(speed_r[present]+speed_r[present-1])/2+    #-Kd_d*derror\n",
    "    #bounded speed for turn\n",
    "    if speed_right<-v_max:speed_right=-v_max\n",
    "    if speed_right>v_max:speed_right=v_max\n",
    "    if speed_left<-v_max:speed_left=-v_max\n",
    "    if speed_left>v_max:speed_left=v_max\n",
    "    #bounded speed for turn+speedDC\n",
    "    delta_speed=abs(speed_left-speed_right)\n",
    "    if speed_left+vitesse>v_max:#PB si les deux au dessus\n",
    "        speed_left=v_max\n",
    "        speed_right=v_max-delta_speed\n",
    "    elif speed_right+vitesse>v_max:\n",
    "        speed_left=v_max-delta_speed\n",
    "        speed_right=v_max\n",
    "    else:\n",
    "        speed_left=speed_left+vitesse\n",
    "        speed_right=speed_right+vitesse\n",
    "    return speed_left,speed_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a87ab0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def navigation(vertex, goal_pos):\n",
    "    state=1 # 0=gradient, 1=obstacle avoidance\n",
    "    obstThrL = 10     \n",
    "    obstThrH = 20     \n",
    "    coef = 5 \n",
    "\n",
    "    goal_nb=0\n",
    "    speed_left=0\n",
    "    speed_right=0\n",
    "    direction=0\n",
    "\n",
    "\n",
    "    obst = [0,0,0,0,0]   \n",
    "    #await node.wait_for_variables({\"prox.horizontal\"})\n",
    "    obst = list(node.v.prox.horizontal)\n",
    "    left_obst= (obst[0] + obst[1])//2\n",
    "    right_obst=(obst[3] + obst[4])//2\n",
    "    if state == 0: \n",
    "        # if at least one prox sensor above treshold, go into obstacle avoidance (or condition)\n",
    "        if (obst[0] > obstThrH):\n",
    "            state = 1\n",
    "        elif (obst[1] > obstThrH):\n",
    "            state = 1\n",
    "        elif (obst[3] > obstThrH):\n",
    "            state = 1\n",
    "        elif (obst[4] > obstThrH):\n",
    "            state = 1\n",
    "      \n",
    "    elif state == 1:\n",
    "      # if all prox sensors under treshold, go back to global nav (and condition)\n",
    "        if obst[0] < obstThrL:\n",
    "            if obst[1] < obstThrL : \n",
    "                if obst[3] < obstThrL : \n",
    "                    if obst[4] < obstThrL : \n",
    "                        state = 0\n",
    "    path=global_path([robot_state[0],robot_state[1]], goal_pos, vertex)           \n",
    "    if  state == 0 :\n",
    "        (speed_left, speed_right)=global_nav(path)\n",
    "        motor_left_target = speed_left\n",
    "        motor_right_target = speed_right\n",
    "        \n",
    "    else:\n",
    "#        leds_top = [30,30,30]\n",
    "        motor_left_target = speed_left - coef * (right_obst// 100)\n",
    "        motor_right_target = speed_right - coef * (left_obst // 100)\n",
    "        #path=global_path([robot_state[0],robot_state[1]], goal_pos, vertex)\n",
    "        \n",
    "    v = {\n",
    "            \"motor.left.target\": [int(motor_left_target*2.3)],\n",
    "            \"motor.right.target\": [int(motor_right_target*2.3)],\n",
    "    }\n",
    "    aw(node.set_variables(v))\n",
    "    #await client.sleep(10*dt) # your long-running job goes here... here wait1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ba9274f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_6632\\759940664.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  vertices = np.array(global_map)#np.array([[[1,2],[3,2],[3,4],[1,4]],[[4,4],[6,4],[5,5]]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between two pixel is: 1.6095569499491262 mm\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/12 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'same_point' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [43], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vertex))\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m################################\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m path\u001b[38;5;241m=\u001b[39m\u001b[43mglobal_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrobot_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrobot_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgoal_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(path)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m state\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m2\u001b[39m:\n",
      "Cell \u001b[1;32mIn [42], line 43\u001b[0m, in \u001b[0;36mglobal_path\u001b[1;34m(start_pos, goal_pos, global_map)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m#polygons[i][range(len(vertices[i]),max_vertices)] = polygons[i][0]\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#print(polygons)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m graph \u001b[38;5;241m=\u001b[39m vg\u001b[38;5;241m.\u001b[39mVisGraph()\n\u001b[1;32m---> 43\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolygons\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#graph.buffer(margin,join_style=2)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m shortest_path \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mshortest_path(start_point,goal_point)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyvisgraph\\vis_graph.py:82\u001b[0m, in \u001b[0;36mVisGraph.build\u001b[1;34m(self, input, workers, status)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m workers \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm([points[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m     80\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m xrange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(points), batch_size)],\n\u001b[0;32m     81\u001b[0m                     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m status):\n\u001b[1;32m---> 82\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m edge \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_vis_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     83\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisgraph\u001b[38;5;241m.\u001b[39madd_edge(edge)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyvisgraph\\vis_graph.py:156\u001b[0m, in \u001b[0;36m_vis_graph\u001b[1;34m(graph, points)\u001b[0m\n\u001b[0;32m    154\u001b[0m visible_edges \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p1 \u001b[38;5;129;01min\u001b[39;00m points:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p2 \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvisible_vertices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhalf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    157\u001b[0m         visible_edges\u001b[38;5;241m.\u001b[39mappend(Edge(p1, p2))\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m visible_edges\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyvisgraph\\visible_vertices.py:110\u001b[0m, in \u001b[0;36mvisible_vertices\u001b[1;34m(point, graph, origin, destination, scan)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (point \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m edge) \u001b[38;5;129;01mand\u001b[39;00m ccw(point, p, edge\u001b[38;5;241m.\u001b[39mget_adjacent(p)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    109\u001b[0m         k \u001b[38;5;241m=\u001b[39m EdgeKey(point, p, edge)\n\u001b[1;32m--> 110\u001b[0m         \u001b[43minsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopen_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m prev \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m    113\u001b[0m prev_visible \u001b[38;5;241m=\u001b[39m is_visible\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyvisgraph\\visible_vertices.py:346\u001b[0m, in \u001b[0;36minsort\u001b[1;34m(a, x)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m lo \u001b[38;5;241m<\u001b[39m hi:\n\u001b[0;32m    345\u001b[0m     mid \u001b[38;5;241m=\u001b[39m (lo\u001b[38;5;241m+\u001b[39mhi)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmid\u001b[49m\u001b[43m]\u001b[49m: hi \u001b[38;5;241m=\u001b[39m mid\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: lo \u001b[38;5;241m=\u001b[39m mid\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    348\u001b[0m a\u001b[38;5;241m.\u001b[39minsert(lo, x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyvisgraph\\visible_vertices.py:388\u001b[0m, in \u001b[0;36mEdgeKey.__lt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge\u001b[38;5;241m.\u001b[39mp2 \u001b[38;5;129;01min\u001b[39;00m other\u001b[38;5;241m.\u001b[39medge:\n\u001b[0;32m    387\u001b[0m     same_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge\u001b[38;5;241m.\u001b[39mp2\n\u001b[1;32m--> 388\u001b[0m aslf \u001b[38;5;241m=\u001b[39m angle2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge\u001b[38;5;241m.\u001b[39mget_adjacent(\u001b[43msame_point\u001b[49m))\n\u001b[0;32m    389\u001b[0m aot \u001b[38;5;241m=\u001b[39m angle2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp2, other\u001b[38;5;241m.\u001b[39medge\u001b[38;5;241m.\u001b[39mget_adjacent(same_point))\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aslf \u001b[38;5;241m<\u001b[39m aot:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'same_point' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "timer_cam=1\n",
    "dt=0.1\n",
    "state=0\n",
    "new_image=0\n",
    "theta=0\n",
    "robot_state=[0,0,0,0] # [x,y,vx,vy]\n",
    "pos_cam=[0,0]\n",
    "Ts = 0.1\n",
    "qp = 0.04 # variance on position state\n",
    "rp = 0.25 # variance on position measurement\n",
    "q_nu= 0.04 #variance on speed state\n",
    "r_nu=0.25 #variance on speed measurement\n",
    "\n",
    "my_map=Map()\n",
    "\n",
    "cap = cv2.VideoCapture(1) #Resolution (640,480):camera provided in class\n",
    "ret, frame = cap.read() #returns ret and the frame\n",
    "globalmap=my_map.compute_globalmap(frame)\n",
    "start_pos=my_map.get_start()\n",
    "robot_state[0]=start_pos[0]\n",
    "robot_state[1]=start_pos[1]\n",
    "goal_pos= my_map.get_goal()\n",
    "vertex= compute_vertex(globalmap)\n",
    "print(len(vertex))\n",
    "################################\n",
    "path=global_path([robot_state[0],robot_state[1]], goal_pos, vertex)\n",
    "print(path)\n",
    "while state!=2:\n",
    "    await client.sleep(timer_cam)\n",
    "    ret, frame = cap.read() #returns ret and the frame\n",
    "    #new_image=1\n",
    "    pos_cam=get_robot_position(frame) #gets x-y measurements from camera and convert to mm\n",
    "    pos_cam[0]=pos_cam[0]*1.6\n",
    "    pos_cam[1]=pos_cam[1]*1.6\n",
    "    \n",
    "    #await node.wait_for_variables({\"motor.right.speed\",\"motor.right.speed\"})\n",
    "    \n",
    "    #vleft=node[\"motor.left.speed\"]\n",
    "    #vright=node[\"motor.right.speed\"]#get motor speed vx and vy converted to mm/s\n",
    "    #vx=((vleft+vright)/2)*np.cos(theta)*2.3\n",
    "    #vy=((vleft+vright)/2)*np.sin(theta)*2.3\n",
    "    #motor_speed=[vx,vy]\n",
    "    #robot_state=kalman(robot_state, pos_cam, motor_speed)\n",
    "    #new_image=0\n",
    "    #start_pos=[robot_state[0], robot_state[1]]\n",
    "    #shortest_path= global_path(start_pos, goal_pos, global_map)\n",
    "    \n",
    "    #await node.wait_for_variables({\"prox.horizontal\"})\n",
    "    \n",
    "    navigation(vertex, goal_pos)\n",
    "    \n",
    "    #await client.sleep(10*dt) # your long-running job goes here... here wait1s\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456a1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
