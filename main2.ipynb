{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node a4a5db65-ab23-417b-975e-12649f3406c8"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "node = await client.wait_for_node()\n",
    "await node.lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filterpy in c:\\users\\noeta\\anaconda3\\lib\\site-packages (1.4.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from filterpy) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from filterpy) (3.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from filterpy) (1.20.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from matplotlib->filterpy) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from matplotlib->filterpy) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from matplotlib->filterpy) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from matplotlib->filterpy) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from matplotlib->filterpy) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->filterpy) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\noeta\\anaconda3\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Requirement already satisfied: pyvisgraph in c:\\users\\noeta\\anaconda3\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\noeta\\anaconda3\\lib\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\noeta\\appdata\\roaming\\python\\python39\\site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\noeta\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "#librairy for kalman\n",
    "!pip install filterpy \n",
    "!pip install tqdm\n",
    "!pip install pyvisgraph\n",
    "!pip install opencv-python\n",
    "!pip install opencv-contrib-python --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from filterpy.common import Q_discrete_white_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "global index,speed_left,speed_right,direction,state,pos_cam, new_image\n",
    "timer_cam=1\n",
    "dt=0.1\n",
    "state=0\n",
    "new_image=0\n",
    "direction=0\n",
    "robot_state=[0,0,0,0] # [x,y,vx,vy]\n",
    "pos_cam=[0,0]\n",
    "Ts = 0.1\n",
    "qp = 0.04 # variance on position state\n",
    "rp = 0.25 # variance on position measurement\n",
    "q_nu= 0.04 #variance on speed state\n",
    "r_nu=0.25 #variance on speed measurement\n",
    "index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map:\n",
    "    # compute_globalmap(self,image,robot_size,start_id=0,goal_id=1):\n",
    "    #  Generate globalmap with obstacle inflation: 0:free 1:occupied 2:start 3:goal\n",
    "    #  return self.globalmap\n",
    "    # compute_pixel_to_distance(self):\n",
    "    #  compute real world distance between two neighborhood pixels;unit:mm\n",
    "    #  **only have the value when goal is detected successfully\n",
    "    #  return self.pixel_to_distance\n",
    "    # compute_start(self,image, start_id=0):\n",
    "    #  Detect start by aruco marker\n",
    "    #  Return start position in (x,y) coordinate; if not detected return None\n",
    "    #  return self.start\n",
    "    # compute_goal(self,image, goal_id=1):\n",
    "    #  Detect goal by aruco marker\n",
    "    #  Return goal position in (x,y) coordinate; if not detected return None\n",
    "    #  return self.goal\n",
    "    # get_pixel_to_distance(self):\n",
    "    #  return self.pixel_to_distance\n",
    "    # get_globalmap(self):\n",
    "    #  return self.globalmap\n",
    "    # get_start(self):\n",
    "    #  return self.start\n",
    "    # get_goal(self):\n",
    "    #  return self.goal\n",
    "\n",
    "    def compute_globalmap(self, image, robot_size=0, start_id=0, goal_id=1):\n",
    "        # Generate globalmap with obstacle inflation: 0:free 1:occupied 2:start 3:goal\n",
    "        # height, width = image.shape[:2]\n",
    "\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Simple threshold method\n",
    "        # ret,thresh = cv2.threshold(gray,50,255,cv2.THRESH_BINARY)\n",
    "\n",
    "\n",
    "        # Otsu's thresholding after Gaussian filtering\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        # cv2.imshow(\"thresh\", thresh)\n",
    "\n",
    "        # Generate Global map\n",
    "        # from 0,255 convert to 0(free),1(occupied);change to (x,y) coordinate\n",
    "        temp_globalmap = np.transpose(np.array(thresh < 255, dtype=int))\n",
    "\n",
    "        # Detect start and goal by aruco marker\n",
    "        # Return start and goal position in (x,y) coordinate; if not detected return None\n",
    "        # start_id: start aruco marker id\n",
    "        # goal_id=: goal aruco marker id\n",
    "\n",
    "        # Define aruco marker detector\n",
    "        arucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "        arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "        # Detect aruco marker\n",
    "        (corners, ids, rejected) = cv2.aruco.detectMarkers(image, arucoDict, parameters=arucoParams)\n",
    "        # print(corners, ids, rejected)\n",
    "        start = None\n",
    "        goal = None\n",
    "        s = 10\n",
    "        if ids is not None:\n",
    "            for corner, number in zip(corners, ids):\n",
    "                (topLeft, topRight, bottomRight, bottomLeft) = corner[0].astype(int)\n",
    "                # print(topLeft, topRight, bottomRight, bottomLeft)\n",
    "                centerpoint = (int((topLeft[0] + bottomRight[0]) / 2), int((topLeft[1] + bottomRight[1]) / 2))\n",
    "                if number == start_id:\n",
    "                    start = centerpoint\n",
    "                    # print(\"start:\",start)\n",
    "                    # print(topLeft, topRight, bottomRight, bottomLeft)\n",
    "                    temp_globalmap[topLeft[0] - s:bottomRight[0] + s, topLeft[1] - s:bottomRight[1] + s] = 0\n",
    "                    # print(temp_globalmap[bottomRight[0]-2:topLeft[0]+2,topLeft[1]-2:bottomRight[1]+2])\n",
    "\n",
    "                elif number == goal_id:\n",
    "                    goal = centerpoint\n",
    "                    # print(\"goal:\",goal)\n",
    "                    # print(topLeft, topRight, bottomRight, bottomLeft)\n",
    "                    temp_globalmap[topLeft[0] - s:bottomRight[0] + s, topLeft[1] - s:bottomRight[1] + s] = 0\n",
    "                    # print(temp_globalmap[bottomRight[0]-2:topLeft[0]+2,topLeft[1]-2:bottomRight[1]+2])\n",
    "                    self.goal_topLeft = topLeft\n",
    "                    self.goal_topRight = topRight\n",
    "                    pixel_to_distance = self.compute_pixel_to_distance()\n",
    "                    # print(\"pixel_to_distance:\",pixel_to_distance)\n",
    "\n",
    "                else:\n",
    "                    temp_globalmap[bottomRight[0] - s:topLeft[0] + s, topLeft[1] - s:bottomRight[1] + s] = 0\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        globalmap = temp_globalmap.copy()\n",
    "\n",
    "        if start is None:\n",
    "            print(\"NOT detect start point\")\n",
    "        else:\n",
    "            #globalmap[temp_globalmap == 2] = 0\n",
    "            pass\n",
    "        if goal is None:\n",
    "            print(\"NOT detect goal point\")\n",
    "        else:\n",
    "            #globalmap[temp_globalmap == 3] = 0\n",
    "            pass\n",
    "\n",
    "        # # obstacle_map:the map only have obstacle inside, no start and goal\n",
    "        # self.obstacle_map = globalmap.copy()\n",
    "\n",
    "        # obstacle inflation\n",
    "        # 3x3 structuring element with connectivity 2\n",
    "        struct = ndimage.generate_binary_structure(2, 2)\n",
    "        # robot_size:radius of robot(unit:mm)\n",
    "        margin = int(robot_size / pixel_to_distance)+1#margin at least need to be 1, can't be 0\n",
    "        print(pixel_to_distance)\n",
    "        #margin=1\n",
    "        globalmap = ndimage.binary_dilation(globalmap, structure=struct, iterations=margin).astype(globalmap.dtype)\n",
    "\n",
    "        # # add start and goal\n",
    "        # globalmap[temp_globalmap == 2] = 2\n",
    "        # globalmap[temp_globalmap == 3] = 3\n",
    "\n",
    "        self.globalmap = globalmap\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "\n",
    "        return self.globalmap\n",
    "\n",
    "    def compute_pixel_to_distance(self):\n",
    "        # for get pixel_to_ditance value, use function \"get_pixel_to_distance\"\n",
    "        # aruco marker:71mmx71mm\n",
    "        # pixel_to_distance:return real world distance between two neighborhood pixels;unit:mm\n",
    "        pixel_to_distance = 71 / math.dist(self.goal_topLeft, self.goal_topRight)  # unit:mm\n",
    "        #print(\"Distance between two pixel is:\", pixel_to_distance, \"mm\")\n",
    "\n",
    "        self.pixel_to_distance = pixel_to_distance\n",
    "\n",
    "        return self.pixel_to_distance\n",
    "\n",
    "    def get_pixel_to_distance(self):\n",
    "        return self.pixel_to_distance\n",
    "\n",
    "    def get_globalmap(self):\n",
    "        return self.globalmap\n",
    "\n",
    "    def get_start(self):\n",
    "        # get the center point of start point\n",
    "        if self.start is None:\n",
    "            print(\"NOT detect start point\")\n",
    "        else:\n",
    "            pass\n",
    "        return self.start\n",
    "\n",
    "    def get_goal(self):\n",
    "        # get the center point of goal point\n",
    "        if self.goal is None:\n",
    "            print(\"NOT detect goal point\")\n",
    "        else:\n",
    "            pass\n",
    "        return self.goal\n",
    "\n",
    "    def compute_start(self, image, start_id=0):\n",
    "        # Detect start by aruco marker\n",
    "        # Return start position in (x,y) coordinate; if not detected return None\n",
    "        # start_id: start aruco marker id\n",
    "\n",
    "        # Define aruco marker detector\n",
    "        arucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "        arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "        # Detect aruco marker\n",
    "        (corners, ids, rejected) = cv2.aruco.detectMarkers(image, arucoDict, parameters=arucoParams)\n",
    "        # print(corners, ids, rejected)\n",
    "        start = None\n",
    "        if ids is not None:\n",
    "            for corner, number in zip(corners, ids):\n",
    "                (topLeft, topRight, bottomRight, bottomLeft) = corner[0].astype(int)\n",
    "                # print(topLeft, topRight, bottomRight, bottomLeft)\n",
    "                centerpoint = (int((topLeft[0] + bottomRight[0]) / 2), int((topLeft[1] + bottomRight[1]) / 2))\n",
    "                if number == start_id:\n",
    "                    start = centerpoint\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "        if start is None:\n",
    "            print(\"NOT detect start point\")\n",
    "        else:\n",
    "            print(\"start position is:\", start)\n",
    "        self.start = start\n",
    "\n",
    "        return self.start\n",
    "\n",
    "    def compute_goal(self, image, goal_id=1):\n",
    "        # Detect goal by aruco marker\n",
    "        # Return goal position in (x,y) coordinate; if not detected return None\n",
    "        # goal_id=: goal aruco marker id\n",
    "\n",
    "        # Define aruco marker detector\n",
    "        arucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "        arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "        # Detect aruco marker\n",
    "        (corners, ids, rejected) = cv2.aruco.detectMarkers(image, arucoDict, parameters=arucoParams)\n",
    "        # print(corners, ids, rejected)\n",
    "        goal = None\n",
    "        if ids is not None:\n",
    "            for corner, number in zip(corners, ids):\n",
    "                (topLeft, topRight, bottomRight, bottomLeft) = corner[0].astype(int)\n",
    "                # print(topLeft, topRight, bottomRight, bottomLeft)\n",
    "                centerpoint = (int((topLeft[0] + bottomRight[0]) / 2), int((topLeft[1] + bottomRight[1]) / 2))\n",
    "                if number == goal_id:\n",
    "                    goal = centerpoint\n",
    "                    self.goal_topLeft = topLeft\n",
    "                    self.goal_topRight = topRight\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "        if goal is None:\n",
    "            print(\"NOT detect goal point\")\n",
    "        else:\n",
    "            print(\"goal position is:\", goal)\n",
    "        self.goal = goal\n",
    "\n",
    "        return self.goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_vertex(globalmap):\n",
    "    # # get rid of start and goal area\n",
    "    # globalmap[globalmap == 2] = 0\n",
    "    # globalmap[globalmap == 3] = 0\n",
    "\n",
    "    globalmap = np.uint8(np.dot(np.transpose(globalmap), 255))\n",
    "\n",
    "    # apply canny edge detection\n",
    "    edges = cv2.Canny(globalmap, 60, 160)\n",
    "\n",
    "    # apply morphology close\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    morph = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # get contours\n",
    "    contours = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # get vertices\n",
    "    vertices = []\n",
    "    for i in range(len(contours[0])):\n",
    "        peri = cv2.arcLength(contours[0][i], True)\n",
    "        approx = cv2.approxPolyDP(contours[0][i], 0.01 * peri, True)\n",
    "        vertice = []\n",
    "        for i in range(len(approx)):\n",
    "            vertice.append(approx[i][0].tolist())\n",
    "        vertices.append(np.array(vertice))\n",
    "\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_robot_position(image,robot_id=0):\n",
    "    #Detect robot position by aruco marker\n",
    "    #Return robot position; if not detected return None\n",
    "    #robot_id: robot aruco marker id\n",
    "\n",
    "    #Define aruco marker detector\n",
    "    arucoDict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "    arucoParams = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "    robot_position = None\n",
    "    angle=None\n",
    "\n",
    "    #Detect Aruco marker\n",
    "    (corners, ids, rejected) = cv2.aruco.detectMarkers(image, arucoDict,parameters=arucoParams)\n",
    "    # print(corners, ids, rejected)\n",
    "    if ids is not None:\n",
    "        #print(\"aruco marker detected:\",ids)\n",
    "        for corner,number in zip(corners,ids):\n",
    "            (topLeft, topRight, bottomRight, bottomLeft) = corner[0]\n",
    "            centerpoint=(int((topLeft[0]+bottomRight[0])/2),int((topLeft[1]+bottomRight[1])/2))\n",
    "            if number==robot_id:\n",
    "                robot_position=centerpoint\n",
    "                angle=angle_calculate(topLeft,topRight)\n",
    "                break\n",
    "            else:pass\n",
    "    else:pass\n",
    "    \n",
    "    return robot_position,angle\n",
    "\n",
    "def angle_calculate(pt1,pt2):  # function which returns angle between two points in the range of 0-359\n",
    "    angle_list = list(range(0,360,1))\n",
    "    x=pt2[0]-pt1[0] \n",
    "    y=pt2[1]-pt1[1]\n",
    "    angle=int(math.degrees(math.atan2(y,x))) #takes 2 points nad give angle with respect to horizontal axis in range(-180,180)\n",
    "    angle = angle_list[angle]\n",
    "    \n",
    "    return int(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kalman(current_state, pos_cam, motor_speed):\n",
    "    global new_image\n",
    "    #estimate x-y position with velocity\n",
    "    #measurements and camera postion measurement\n",
    "    f = KalmanFilter (dim_x=4, dim_z=4)\n",
    "\n",
    "    # initial position\n",
    "    f.x= np.transpose(current_state)\n",
    "    print(current_state)\n",
    "    \n",
    "    #state transition matrix\n",
    "   \n",
    "    f.F = np.array([[1, 0, Ts, 0],\n",
    "              [0, 1, 0, Ts], \n",
    "              [0, 0, 1, 0],\n",
    "              [0, 0, 0, 1]])\n",
    "\n",
    "    #measurement function H\n",
    "    f.H = np.array([[1, 0, 0, 0],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1]])\n",
    "\n",
    "    #covariance matrix P\n",
    "    f.P = np.array([[qp, 0, 0, 0], \n",
    "              [0, qp, 0, 0], \n",
    "              [0, 0, q_nu, 0], \n",
    "              [0, 0, 0, q_nu]])\n",
    "\n",
    "    #measurement noise R (scalar)\n",
    "    f.R = np.array([[rp, 0, 0, 0],\n",
    "                [0, rp, 0, 0],\n",
    "                [0, 0, r_nu, 0],\n",
    "                [0, 0, 0, r_nu]])\n",
    "\n",
    "    #process noise Q\n",
    "    f.Q = Q_discrete_white_noise(dim=4, dt=0.1, var=0.13)\n",
    "    \n",
    "    if(new_image): #if image is up to date, take position from camera\n",
    "        #print(motor_speed)\n",
    "        #print(pos_cam)\n",
    "        new_image=0#\n",
    "        z = np.transpose(np.array([pos_cam[0],pos_cam[1], motor_speed[0],motor_speed[1]]))\n",
    "    else:\n",
    "    #pos=np.array([) #if image outdated, use state position instead of camera position\n",
    "        z = np.array([current_state[0], current_state[1], motor_speed[0],motor_speed[1]])\n",
    "    \n",
    "    f.predict()\n",
    "    f.update(z)\n",
    "    print(f.x)\n",
    "    #return state and covariance matrix\n",
    "    return f.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global path\n",
    "\n",
    "def global_path(start_pos, goal_pos, global_map):\n",
    "\n",
    "    import pyvisgraph as vg\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    start = np.array(start_pos)#np.array([0.5,0.5])\n",
    "    goal = np.array(goal_pos)#np.array([5.25,6])\n",
    "    print(start)\n",
    "    print(goal)\n",
    "\n",
    "    start_point = vg.Point(start[0], start[1])\n",
    "    goal_point = vg.Point(goal[0], goal[1])\n",
    "\n",
    "    vertices = np.array(global_map)#np.array([[[1,2],[3,2],[3,4],[1,4]],[[4,4],[6,4],[5,5]]])\n",
    "   \n",
    "\n",
    "    vertices = np.asarray(vertices)\n",
    "    print(vertices)\n",
    "\n",
    "    #plt.plot(vertices)\n",
    "    #plt.show\n",
    "\n",
    "    # Automate the creation of vg.Points for the obstacles\n",
    "\n",
    "    max_vertices = 0\n",
    "\n",
    "    for i in range(len(vertices)):\n",
    "        if(len(vertices[i])>max_vertices):\n",
    "            max_vertices = len(vertices[i])\n",
    "\n",
    "    polygons = [[0 for i in range(max_vertices+1)] for j in range(len(vertices))]\n",
    "\n",
    "    for i in range(len(vertices)):\n",
    "        for j in range(len(vertices[i])):\n",
    "            polygons[i][j] = vg.Point(vertices[i][j][0],vertices[i][j][1])\n",
    "        polygons[i][(len(vertices[i])):(max_vertices+1)] = [polygons[i][0] for k in range(len(vertices[i]),max_vertices+1)]\n",
    "        #polygons[i][range(len(vertices[i]),max_vertices)] = polygons[i][0]\n",
    "\n",
    "    graph = vg.VisGraph()\n",
    "    graph.build(polygons)\n",
    "    #graph.buffer(margin,join_style=2)\n",
    "\n",
    "    shortest_path = graph.shortest_path(start_point,goal_point)\n",
    "\n",
    "    print(shortest_path)\n",
    "\n",
    "    polygons_x = np.empty((len(polygons),len(polygons[1])+1))\n",
    "    polygons_y = np.empty((len(polygons),len(polygons[1])+1))\n",
    "\n",
    "    for i in range(len(polygons)):\n",
    "        for j in range(len(polygons[i])):\n",
    "            polygons_x[i][j] = polygons[i][j].x\n",
    "            polygons_y[i][j] = polygons[i][j].y\n",
    "        polygons_x[i][len(polygons[1])] = polygons_x[i][0]\n",
    "        polygons_y[i][len(polygons[1])] = polygons_y[i][0]\n",
    "\n",
    "    shortest_path_x = np.empty(len(shortest_path))\n",
    "    shortest_path_y = np.empty(len(shortest_path))\n",
    "    \n",
    "    shortest = [[0 for i in range(2)] for j in range(len(shortest_path))]\n",
    "\n",
    "    for i in range(len(shortest_path)):\n",
    "        shortest_path_x[i] = shortest_path[i].x\n",
    "        shortest_path_y[i] = shortest_path[i].y\n",
    "        shortest[i][0] = shortest_path[i].x\n",
    "        shortest[i][1] = shortest_path[i].y\n",
    "\n",
    "    plt.plot(shortest_path_x,shortest_path_y)\n",
    "    plt.plot(polygons_x.T,polygons_y.T)\n",
    "    plt.show()\n",
    "    return shortest\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_nav(path):\n",
    "    global state,index\n",
    "    \n",
    "    #constantes\n",
    "    v_max=400#mm/s\n",
    "    #v_min=20\n",
    "    Diameter=94#mm\n",
    "    goal_margin=30#mm\n",
    "    threshold=0.3\n",
    "    \n",
    "    #just to tune by test, names wrong\n",
    "    Kp_d=0.1\n",
    "    #CHECK GOAL\n",
    "    if math.sqrt((robot_state[0]-path[index,0])**2+(robot_state[1]-path[index,1])**2)<goal_margin:\n",
    "        if index+1>=np.size(path[:,0]):\n",
    "            print('arrived')\n",
    "            state=2\n",
    "            return 0,0#works only in a function\n",
    "        else:\n",
    "            index=index+1\n",
    "            print('index : ',index)\n",
    "    \n",
    "    #MOTORS\n",
    "    obj_angle=np.arctan2(path[index,1]-robot_state[1],path[index,0]-robot_state[0])-direction\n",
    "    while(obj_angle>np.pi):\n",
    "        obj_angle=obj_angle-np.pi\n",
    "    while(obj_angle<-np.pi):\n",
    "        obj_angle=obj_angle+np.pi\n",
    "    if abs(obj_angle)>threshold:\n",
    "        vitesse=0#-Kd_v*abs(obj_angle-direction[present])+Kp_v*abs(50-vitesse[present])#vitesse[present]\n",
    "        if vitesse<0:vitesse=0##v_min\n",
    "    else:\n",
    "        vitesse=100#-Ki_v*abs(50-vitesse[present])\n",
    "    #derror=obj_dir(*position[present,:],*path[goal,:])+obj_dir(*position[present-1,:],*path[goal,:])-direction[present]-direction[present-1]\n",
    "    speed_left=-(Kp_d*(obj_angle-direction))*Diameter#vitesse[present+1]    #0.2*(speed_l[present]+speed_l[present-1])/2    #-Kd_d*derror\n",
    "    speed_right=(Kp_d*(obj_angle-direction))*Diameter#vitesse[present+1]    #0.2*(speed_r[present]+speed_r[present-1])/2+    #-Kd_d*derror\n",
    "    #bounded speed for turn\n",
    "    if speed_right<-v_max:speed_right=-v_max\n",
    "    if speed_right>v_max:speed_right=v_max\n",
    "    if speed_left<-v_max:speed_left=-v_max\n",
    "    if speed_left>v_max:speed_left=v_max\n",
    "    #bounded speed for turn+speedDC\n",
    "    delta_speed=abs(speed_left-speed_right)\n",
    "    if speed_left+vitesse>v_max:#PB si les deux au dessus\n",
    "        speed_left=v_max\n",
    "        speed_right=v_max-delta_speed\n",
    "    elif speed_right+vitesse>v_max:\n",
    "        speed_left=v_max-delta_speed\n",
    "        speed_right=v_max\n",
    "    else:\n",
    "        speed_left=speed_left+vitesse\n",
    "        speed_right=speed_right+vitesse\n",
    "    return speed_left,speed_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigation(path,obst):#vertex, goal_pos):\n",
    "    global index,speed_left,speed_right,direction,state\n",
    "    #state=1 # 0=gradient, 1=obstacle avoidance\n",
    "    obstThrL = 10     \n",
    "    obstThrH = 20     \n",
    "    coef = 5 \n",
    "\n",
    "    #goal_nb=0\n",
    "    #speed_left=0\n",
    "    #speed_right=0\n",
    "    #direction=0\n",
    "\n",
    "\n",
    "    #obst = np.array([0,0,0,0,0])  \n",
    "    #await node.wait_for_variables({\"prox.horizontal\"})\n",
    "    #obst = list(node.v.prox.horizontal)\n",
    "    left_obst= (obst[0] + obst[1])//2\n",
    "    right_obst=(obst[3] + obst[4])//2\n",
    "    if state == 0:\n",
    "        # if at least one prox sensor above treshold, go into obstacle avoidance (or condition)\n",
    "        if (obst[0] > obstThrH):\n",
    "            state = 1\n",
    "        elif (obst[1] > obstThrH):\n",
    "            state = 1\n",
    "        elif (obst[3] > obstThrH):\n",
    "            state = 1\n",
    "        elif (obst[4] > obstThrH):\n",
    "            state = 1\n",
    "    elif state == 1:\n",
    "      # if all prox sensors under treshold, go back to global nav (and condition)\n",
    "        if obst[0] < obstThrL:\n",
    "            if obst[1] < obstThrL : \n",
    "                if obst[3] < obstThrL : \n",
    "                    if obst[4] < obstThrL : \n",
    "                        state = 0\n",
    "    #path=global_path([robot_state[0],robot_state[1]], goal_pos, vertex)           \n",
    "    if  state  == 0:\n",
    "        (speed_left, speed_right)=global_nav(path)#,goal_pos)\n",
    "        motor_left_target = speed_left\n",
    "        motor_right_target = speed_right\n",
    "    else:\n",
    "#        leds_top = [30,30,30]\n",
    "        motor_left_target = speed_left - coef * (right_obst// 100)\n",
    "        motor_right_target = speed_right - coef * (left_obst // 100)\n",
    "        #path=global_path([robot_state[0],robot_state[1]], goal_pos, vertex)\n",
    "        \n",
    "    v = {\n",
    "            \"motor.left.target\": [int(motor_left_target*2.3)],\n",
    "            \"motor.right.target\": [int(motor_right_target*2.3)],\n",
    "    }\n",
    "    aw(node.set_variables(v))\n",
    "    #await client.sleep(10*dt) # your long-running job goes here... here wait1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Timer\n",
    "\n",
    "class RepeatedTimer(object):\n",
    "    def __init__(self, interval, function, *args, **kwargs):\n",
    "        self._timer     = None\n",
    "        self.interval   = interval\n",
    "        self.function   = function\n",
    "        self.args       = args\n",
    "        self.kwargs     = kwargs\n",
    "        self.is_running = False\n",
    "        self.start()\n",
    "\n",
    "    def _run(self):\n",
    "        self.is_running = False\n",
    "        self.start()\n",
    "        self.function(*self.args, **self.kwargs)\n",
    "\n",
    "    def start(self):\n",
    "        if not self.is_running:\n",
    "            self._timer = Timer(self.interval, self._run)\n",
    "            self._timer.start()\n",
    "            self.is_running = True\n",
    "\n",
    "    def stop(self):\n",
    "        self._timer.cancel()\n",
    "        self.is_running = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire_data = False\n",
    "#Ts = 0.1\n",
    "thymio_data = []\n",
    "\n",
    "def motors(left, right):\n",
    "    return {\n",
    "        \"motor.left.target\": [left],\n",
    "        \"motor.right.target\": [right],\n",
    "    }\n",
    "\n",
    "def get_data():\n",
    "    thymio_data.append({\"prox\":list(node[\"prox.horizontal\"]),#not really useful??\n",
    "                        \"left_speed\":node[\"motor.left.speed\"],#for std\n",
    "                        \"right_speed\":node[\"motor.right.speed\"]})#for std\n",
    "    #print(\"prox/mot\")\n",
    "    \n",
    "def get_picture():\n",
    "    #print(\"picture\")\n",
    "    #ret, frame = cap.read() #returns ret and the frame\n",
    "    #pos_cam=get_robot_position(frame) #gets x-y measurements from camera and convert to mm\n",
    "    #pos_cam[0]=pos_cam[0]*1.6\n",
    "    #pos_cam[1]=pos_cam[1]*1.6\n",
    "    new_image=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.17992195 0.10829693]\n",
      "entre\n",
      "[0.01339591 0.00833347 0.15156374 0.05967825]\n",
      "[0.01339591 0.00833347 0.15156374 0.05967825]\n",
      "entre\n",
      "[0.02467028 0.01293795 0.1285139  0.03149339]\n",
      "[0.02467028 0.01293795 0.1285139  0.03149339]\n",
      "entre\n",
      "[ 0.03361982  0.01370241  0.09692594 -0.05768498]\n",
      "[ 0.03361982  0.01370241  0.09692594 -0.05768498]\n",
      "entre\n",
      "[0.04211868 0.01025416 0.10348131 0.00728633]\n",
      "[0.04211868 0.01025416 0.10348131 0.00728633]\n",
      "entre\n",
      "[0.0498693  0.01088913 0.089562   0.00403096]\n",
      "[0.0498693  0.01088913 0.089562   0.00403096]\n",
      "entre\n",
      "[ 0.05348906  0.00844706  0.0317817  -0.12694296]\n",
      "[ 0.05348906  0.00844706  0.0317817  -0.12694296]\n",
      "entre\n",
      "[ 0.05141079  0.00064593 -0.01566143 -0.00889121]\n",
      "[ 0.05141079  0.00064593 -0.01566143 -0.00889121]\n",
      "entre\n",
      "[6.72100601e-02 1.02803284e-04 1.89454401e-01 5.34323054e-02]\n",
      "[6.72100601e-02 1.02803284e-04 1.89454401e-01 5.34323054e-02]\n",
      "entre\n",
      "[0.09709965 0.00803241 0.36167985 0.23651768]\n",
      "[0.09709965 0.00803241 0.36167985 0.23651768]\n",
      "entre\n",
      "[0.1307419  0.03297339 0.40566174 0.43820776]\n"
     ]
    }
   ],
   "source": [
    "global index,speed_left,speed_right,direction,state,pos_cam, new_image\n",
    "\n",
    "v = {\n",
    "        \"motor.left.target\": [0],\n",
    "        \"motor.right.target\": [0],\n",
    "    }\n",
    "aw(node.set_variables(v))\n",
    "\n",
    "#cap = cv2.VideoCapture(1) #Resolution (640,480):camera provided in class\n",
    "#ret, frame = cap.read() #returns ret and the frame\n",
    "#globalmap=my_map.compute_globalmap(frame)\n",
    "#start_pos=my_map.get_start()\n",
    "robot_state[0]=0#start_pos[0]\n",
    "robot_state[1]=0#start_pos[1]\n",
    "#goal_pos= my_map.get_goal()\n",
    "#vertex= compute_vertex(globalmap)\n",
    "#drawmap=globalmap.copy()\n",
    "#drawmap[drawmap == 2] = 0\n",
    "#drawmap[drawmap == 3] = 0\n",
    "#drawmap = np.float32(np.dot(np.transpose(drawmap),255))\n",
    "#cv2.imshow(\"img\",frame)\n",
    "#cv2.imshow(\"draw\",drawmap)\n",
    "#cv2.waitKey(0)\n",
    "new_image=0\n",
    "start_pos=[robot_state[0], robot_state[1]]\n",
    "#shortest_path= global_path(start_pos, goal_pos, global_map)\n",
    "\n",
    "#launch timers (measure prox/motor;picture)\n",
    "await node.wait_for_variables()\n",
    "t1= RepeatedTimer(0.01, get_data)\n",
    "t2= RepeatedTimer(1, get_picture)\n",
    "#my_map=Map()\n",
    "#print(vertex)\n",
    "for i in range(10):#while state!=2: \n",
    "    await client.sleep(0.1)#timer_cam)#useful??\n",
    "    ##await node.wait_for_variables({\"motor.right.speed\",\"motor.right.speed\",\"prox.horizontal\"})\n",
    "    ##speed_left=node[\"motor.left.speed\"]\n",
    "    ##speed_right=node[\"motor.right.speed\"]#get motor speed vx and vy converted to mm/s\n",
    "    ##print(\"prox,motleft\",list(node.v.prox.horizontal),node[\"motor.left.speed\"])\n",
    "    #await node.wait_for_variables({\"prox.horizontal\"})\n",
    "    obst = list(node.v.prox.horizontal)\n",
    "    #speed_left=node[\"motor.left.speed\"]\n",
    "    #speed_right=node[\"motor.right.speed\"]#get motor speed vx and vy converted to mm/s\n",
    "    prox = [x[\"prox\"] for x in thymio_data]\n",
    "    \n",
    "    speed_left = np.mean([x[\"left_speed\"] for x in thymio_data])#  big list==>std for motors??\n",
    "    speed_right = np.mean([x[\"right_speed\"] for x in thymio_data])\n",
    "    #print(\"\\nleft : \",speed_left,\"\\nright : \",speed_right)\n",
    "    path=np.array([[0,500],[0,-500],[657,254]])\n",
    "    vx=((speed_left+speed_right)/2)*np.cos(direction)\n",
    "    vy=((speed_left+speed_right)/2)*np.sin(direction)\n",
    "    motor_speed=np.array([vx,vy])\n",
    "    robot_state=kalman(robot_state,pos_cam, motor_speed)\n",
    "    direction=direction+np.arctan2(robot_state[3],robot_state[2])\n",
    "    navigation(path,obst)#,vertex,goal_pos)\n",
    "    \n",
    "t1.stop()\n",
    "t2.stop()\n",
    "v = {\n",
    "        \"motor.left.target\": [0],\n",
    "        \"motor.right.target\": [0],\n",
    "    }\n",
    "aw(node.set_variables(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = {\n",
    "        \"motor.left.target\": [0],\n",
    "        \"motor.right.target\": [0],\n",
    "    }\n",
    "aw(node.set_variables(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.393984980731184\n"
     ]
    }
   ],
   "source": [
    "print(np.arctan2( 7.8256149,1.39825887))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
